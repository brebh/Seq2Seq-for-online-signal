{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1000362359804103118\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import time \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import cv2\n",
    "#print (cv2.__version__)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Architecture_gru(Input, outputs, is_training=True):\n",
    "    with tf.variable_scope(\"Network\"):\n",
    "        \n",
    "        with tf.variable_scope(\"CNN\"):\n",
    "            \n",
    "            conv1=tf.layers.conv2d(Input,28,3,activation=tf.nn.relu,name='conv1',padding='same')\n",
    "             #conv1=tf.layers.conv2d(Input,64,3,activation=tf.nn.relu,name='conv1',padding='same')\n",
    "            pool1=tf.layers.max_pooling2d(conv1,2,[2,2],name='pool1')\n",
    "            print('shape conv1',conv1.shape)\n",
    "            print('shape pool1 [2,2]',pool1.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv2=tf.layers.conv2d(pool1,64,3,activation=tf.nn.relu,name='conv2',padding='same')\n",
    "            #conv2=tf.layers.conv2d(pool1,128,3,activation=tf.nn.relu,name='conv2',padding='same')\n",
    "            pool2=tf.layers.max_pooling2d(conv2,2,[2,1],name='pool2')\n",
    "            print('shape conv2',conv2.shape)\n",
    "            print('shape pool2 [2,1]',pool1.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv3=tf.layers.conv2d(pool2,128,3,activation=None,name='conv3',padding='same')\n",
    "            #conv3=tf.layers.conv2d(pool2,256,3,activation=None,name='conv3',padding='same')\n",
    "            b_norm3=tf.nn.relu(tf.layers.batch_normalization(conv3,training=is_training,name='batch-norm1'),name='b_norm3')\n",
    "            print('shape conv3',conv3.shape)\n",
    "            print('shape b_norm3',b_norm3.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv4=tf.layers.conv2d(b_norm3,256,3,activation=tf.nn.relu,name='conv4',padding='same')\n",
    "            pool4=tf.layers.max_pooling2d(conv4,2,[2,1],name='pool4',padding='same')\n",
    "            print('shape conv4',conv4.shape)\n",
    "            print('shape pool4 [2,1]',pool4.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv5=tf.layers.conv2d(pool4,256,3,activation=tf.nn.relu,name='conv5',padding='same')\n",
    "            pool5=tf.layers.max_pooling2d(conv5,2,[2,1],name='pool5',padding='same')\n",
    "            print('shape conv5',conv5.shape)\n",
    "            print('shape pool5 [2,1]',pool5.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv6=tf.layers.conv2d(pool5,256,3,activation=None,name='conv6',padding='same')\n",
    "            b_norm6=tf.nn.relu(tf.layers.batch_normalization(conv6,training=is_training,name='batch-norm2'),name='b_norm6')\n",
    "            print('shape conv6',conv6.shape)  \n",
    "            print('shape b_norm6',b_norm6.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv7=tf.layers.conv2d(b_norm6,256,3,activation=tf.nn.relu,name='conv7',padding='same')\n",
    "            pool7=tf.layers.max_pooling2d(conv7,2,[2,1],name='pool7',padding='same')\n",
    "            print('shape conv7',conv7.shape)\n",
    "            print('shape pool7[2,1]',pool7.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            conv8=tf.layers.conv2d(pool7,256,1,activation=None,name='conv8')\n",
    "            #conv8=tf.layers.conv2d(pool7,256,2,activation=None,name='conv8')\n",
    "            #conv8=tf.layers.conv2d(pool7,512,2,activation=None,name='conv8')\n",
    "            b_norm8=tf.nn.relu(tf.layers.batch_normalization(conv8,training=is_training,name='batch-norm3'),name='b_norm8')\n",
    "            print('shape conv8',conv8.shape)\n",
    "            print('shape b_norm8',b_norm8.shape)\n",
    "            print('************************')\n",
    "            \n",
    "            shape=b_norm8.get_shape().as_list()\n",
    "\n",
    "            transposed=tf.transpose(b_norm8, perm=[0,2,1,3],name='transposed')\n",
    "            conv_reshaped=tf.reshape(transposed, [shape[0], -1, shape[1]*shape[3]], name='reshaped')\n",
    "            #print('shape conv_reshaped',conv_reshaped.shape)#shape conv_reshaped (32, 30, 256)\n",
    "            \n",
    "            \n",
    "            \n",
    "        num_units=256\n",
    "       # num_units=512\n",
    "        num_layers=3\n",
    "        \n",
    "\n",
    "       \n",
    "        cell_stack_encoder=[]\n",
    "        cell_stack_decoder=[]    \n",
    "        \n",
    "        with tf.variable_scope(\"Encoder\"):\n",
    "            for i in range(num_layers):\n",
    "                cell_stack_encoder.append(tf.contrib.rnn.GRUCell(num_units))\n",
    "            encoder_cell=tf.contrib.rnn.MultiRNNCell(cell_stack_encoder)\n",
    "               \n",
    "            _, encoder_state=tf.nn.dynamic_rnn(encoder_cell, conv_reshaped, dtype=tf.float32) \n",
    "           \n",
    "            \n",
    "            print('encoder_state', _.get_shape())\n",
    "              \n",
    "        with tf.variable_scope(\"Decoder\"):\n",
    "            for i in range(num_layers):\n",
    "                cell_stack_decoder.append(tf.contrib.rnn.GRUCell(num_units))\n",
    "            decoder_cell=tf.contrib.rnn.MultiRNNCell(cell_stack_decoder)\n",
    "            \n",
    "            dec_outputs,_=tf.nn.dynamic_rnn(decoder_cell,outputs, initial_state=encoder_state, dtype=tf.float32)\n",
    "           \n",
    "          \n",
    "            \n",
    "            logits=tf.layers.dense(dec_outputs,2, name='logits')\n",
    "            \n",
    "            return logits\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape conv1 (2, 64, 64, 28)\n",
      "shape pool1 [2,2] (2, 32, 32, 28)\n",
      "************************\n",
      "shape conv2 (2, 32, 32, 64)\n",
      "shape pool2 [2,1] (2, 32, 32, 28)\n",
      "************************\n",
      "shape conv3 (2, 16, 31, 128)\n",
      "shape b_norm3 (2, 16, 31, 128)\n",
      "************************\n",
      "shape conv4 (2, 16, 31, 256)\n",
      "shape pool4 [2,1] (2, 8, 31, 256)\n",
      "************************\n",
      "shape conv5 (2, 8, 31, 256)\n",
      "shape pool5 [2,1] (2, 4, 31, 256)\n",
      "************************\n",
      "shape conv6 (2, 4, 31, 256)\n",
      "shape b_norm6 (2, 4, 31, 256)\n",
      "************************\n",
      "shape conv7 (2, 4, 31, 256)\n",
      "shape pool7[2,1] (2, 2, 31, 256)\n",
      "************************\n",
      "shape conv8 (2, 2, 31, 256)\n",
      "shape b_norm8 (2, 2, 31, 256)\n",
      "************************\n",
      "encoder_state (2, 31, 256)\n",
      "INFO:tensorflow:Restoring parameters from /home/razen/tf-notebooks/logs_L3_64gru_3layer_256_LMCA/logs_L3_64gru_3layer_256_LMCA.ckpt-1\n",
      "b 0\n",
      "debut b*BatchSize_Test 0\n",
      "fin batch_Test_input index 2\n"
     ]
    }
   ],
   "source": [
    "def load_Images(Data_Train_Path):\n",
    "    #main_path=[f for f in np.sort(os.listdir(Data_Train_Path)) if f.endswith('redraw')]\n",
    "    main_path=[f for f in np.sort(os.listdir(Data_Train_Path)) if f.endswith('redraw')]\n",
    "    \n",
    "    imgs=[]\n",
    "    for s in main_path:\n",
    "        sub=Data_Train_Path+s\n",
    "        sub_path= [f for f in np.sort(os.listdir(sub))if f.endswith('.tif')]\n",
    "        for t in sub_path:\n",
    "            im_path=sub + '/' +t\n",
    "            img=cv2.imread(im_path,cv2.IMREAD_UNCHANGED)\n",
    "            imgs.append(img)\n",
    "           \n",
    "    return (np.expand_dims(imgs, -1),t)\n",
    "\n",
    "\n",
    "##*****************************************************************************************************\n",
    "Save_folder ='/home/razen/thèse_2018/second_contrib/code/Besma_code_Recovery/recover_IRONOFF_caracters/LMCA_arabe_with_velocity/test_one_letter_recov_2018/fausse/recov/'\n",
    "\n",
    "model_train_path = \"/home/razen/tf-notebooks/logs_L3_64gru_3layer_256_LMCA/logs_L3_64gru_3layer_256_LMCA.ckpt-1\"\n",
    "\n",
    "\n",
    "number = 0\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "tf.reset_default_graph()\n",
    "global sess\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session (config=config)\n",
    "graph = tf.get_default_graph()\n",
    "import os\n",
    "\n",
    "my_DataTest,f = load_Images('/home/razen/thèse_2018/second_contrib/code/Besma_code_Recovery/recover_IRONOFF_caracters/LMCA_arabe_with_velocity/test_one_letter_recov_2018/')\n",
    "\n",
    "\n",
    "\n",
    "[Tot_Dat, row, col, depth] = np.shape(my_DataTest)\n",
    "\n",
    "\n",
    "BatchSize_Test = 2\n",
    "\n",
    "Inputs = tf.placeholder(tf.float32, shape = [BatchSize_Test, 64, 64, 1],name = 'Inputs')\n",
    "outputs = tf.placeholder(tf.float32, shape = [BatchSize_Test, None, 2],name = 'outputs')\n",
    "\n",
    "    \n",
    "logits = Architecture_gru(Inputs, outputs)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, model_train_path)\n",
    "   \n",
    "    start = time.time()\n",
    "    Test_loss = []\n",
    "\n",
    "    \n",
    "    for b in range(Tot_Dat//BatchSize_Test):\n",
    "        batch_Test_input = my_DataTest[b*BatchSize_Test:(b + 1)*BatchSize_Test,:,:,:]\n",
    "        print('b',b)\n",
    "        print('debut b*BatchSize_Test',b*BatchSize_Test)\n",
    "        print('fin batch_Test_input index',(b + 1)*BatchSize_Test)\n",
    "        \n",
    "        \n",
    "        batch_Test_outputs = np.zeros(shape = [BatchSize_Test,1,2])\n",
    "                  \n",
    "        for ij in range(50):\n",
    "               \n",
    "            test_feed_dict = {Inputs:batch_Test_input, outputs:batch_Test_outputs}\n",
    "            logits_Out = sess.run([logits], feed_dict = test_feed_dict)\n",
    "            \n",
    "            logits_Out = logits_Out[0]\n",
    "            \n",
    "            prediction = np.expand_dims(logits_Out[:,-1,:],axis = 1)\n",
    "            batch_Test_outputs = np.hstack([batch_Test_outputs, prediction])\n",
    "            \n",
    "\n",
    "        ############################################\n",
    "        for num in range(2):\n",
    "            \n",
    "            directory = Save_folder \n",
    "            try:\n",
    "                os.stat(directory)\n",
    "            except:\n",
    "                os.mkdir(directory) \n",
    "\n",
    "            np.savetxt(  directory + 'Predict_' + str(num)+str(number) + '.txt', logits_Out[num,:,:])\n",
    "            \n",
    "            number = number + 1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
